{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMT Implementation in Python using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/\n",
    "\n",
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text\n",
    "\n",
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi.', 'Hallo!'],\n",
       "       ['Hi.', 'Grüß Gott!'],\n",
       "       ['Run!', 'Lauf!'],\n",
       "       ...,\n",
       "       ['The man died of cancer.', 'Der Mann starb an Krebs.'],\n",
       "       ['The man lay motionless.', 'Der Mann lag bewegungslos da.'],\n",
       "       ['The man must be insane.', 'Der Mann muss geistesgestört sein.']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deu_eng = deu_eng[:50000,:]\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi', 'Hallo'],\n",
       "       ['Hi', 'Grüß Gott'],\n",
       "       ['Run', 'Lauf'],\n",
       "       ...,\n",
       "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
       "        'Wenn jemand Fremdes dir sagt dass du dich wie ein Muttersprachler anhörst bedeutet das wahrscheinlich Er hat etwas an deinem Sprechen bemerkt dass dich als NichtMuttersprachler verraten hat Mit anderen Worten Du hörst dich nicht wirklich wie ein Muttersprachler an'],\n",
       "       ['It may be impossible to get a completely errorfree corpus due to the nature of this kind of collaborative effort However if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning we might be able to minimize errors',\n",
       "        'Es ist wohl unmöglich einen vollkommen fehlerfreien Korpus zu erreichen\\xa0— das liegt in der Natur eines solchen Gemeinschaftsprojekts Doch wenn wir unsere Mitglieder dazu bringen können nicht mit Sprachen herumzuexperimentieren die sie gerade lernen sondern Sätze in ihrer eigenen Muttersprache beizutragen dann gelingt es uns vielleicht die Zahl der Fehler klein zu halten'],\n",
       "       ['Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people and out of the few hundred that there are but a dozen or less whom he knows intimately and out of the dozen one or two friends at most it will easily be seen when we remember the number of millions who inhabit this world that probably since the earth was created the right man has never yet met the right woman',\n",
       "        'Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt wenn man jedoch in Betracht zieht dass ein Mensch nur Gelegenheit hat mit ein paar hundert anderen bekannt zu sein von denen ihm nur ein Dutzend oder weniger nahesteht darunter höchstens ein oder zwei Freunde dann erahnt man eingedenk der Millionen Einwohner dieser Welt\\xa0leicht dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hi', 'hallo'],\n",
       "       ['hi', 'grüß gott'],\n",
       "       ['run', 'lauf'],\n",
       "       ...,\n",
       "       ['if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker',\n",
       "        'wenn jemand fremdes dir sagt dass du dich wie ein muttersprachler anhörst bedeutet das wahrscheinlich er hat etwas an deinem sprechen bemerkt dass dich als nichtmuttersprachler verraten hat mit anderen worten du hörst dich nicht wirklich wie ein muttersprachler an'],\n",
       "       ['it may be impossible to get a completely errorfree corpus due to the nature of this kind of collaborative effort however if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning we might be able to minimize errors',\n",
       "        'es ist wohl unmöglich einen vollkommen fehlerfreien korpus zu erreichen\\xa0— das liegt in der natur eines solchen gemeinschaftsprojekts doch wenn wir unsere mitglieder dazu bringen können nicht mit sprachen herumzuexperimentieren die sie gerade lernen sondern sätze in ihrer eigenen muttersprache beizutragen dann gelingt es uns vielleicht die zahl der fehler klein zu halten'],\n",
       "       ['doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people and out of the few hundred that there are but a dozen or less whom he knows intimately and out of the dozen one or two friends at most it will easily be seen when we remember the number of millions who inhabit this world that probably since the earth was created the right man has never yet met the right woman',\n",
       "        'ohne zweifel findet sich auf dieser welt zu jedem mann genau die richtige ehefrau und umgekehrt wenn man jedoch in betracht zieht dass ein mensch nur gelegenheit hat mit ein paar hundert anderen bekannt zu sein von denen ihm nur ein dutzend oder weniger nahesteht darunter höchstens ein oder zwei freunde dann erahnt man eingedenk der millionen einwohner dieser welt\\xa0leicht dass seit erschaffung ebenderselben wohl noch nie der richtige mann der richtigen frau begegnet ist']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHuhJREFUeJzt3X2QXNV55/Hvz5KxARtLgJnIErHktcIGQ8BogrTxljNr2WKAxCIJxCJsECy78rp4TahahGur5MWQkrfsYLR2iGWQkSgHWZYhaI1A1mKmEtcigXgJIAirsZDRGFkCS7wIbIjIs3/c0+JO3zs9PZqe6e6Z36eqq/s+96VPt+7o6XPuuecoIjAzM8t7V7MLYGZmrcfJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMYASbdJur7Z5TCzscPJwczMCpwczMyswMmhDUn6uKRHJb0m6XvAe3Pr/kDS45JelvR/Jf1Obl1I+mhu2c1R1hYkfUjSDyS9KOk5SVek+JckrZG0Kv09bJXUmdvvNEmPpXXfl/Q9n/P1cXJoM5IOA/4euB04Gvg+8Cdp3WnACuDzwDHAt4B1kt7TnNKaDZ+kdwH/G/gnYCowF7hK0hlpk88Cq4FJwDrgG2m/w4C7gNvI/lbuAP5oNMvezpwc2s8c4N3A1yPiXyJiLfBwWvdfgG9FxOaIeDsiVgJvpn3M2tXvAh+MiOsi4q2I2A58G1iQ1v8kItZHxNtkP5pOSfE5wERgWfpbuRN4aLQL364mNrsANmQfAn4e/UdM/Fl6/jCwUNLluXWHpX3M2tWHgQ9JejkXmwD8I9m5/4tc/A3gvZImUv63snOkCztWuObQfnYBUyUpF/vN9LwTuCEiJuUeR0TEHWn9G8ARuf1+YxTKazZcO4Hnqs7r90fEWYPsV/a3cvzIFXNscXJoPw8CB4ArJE2U9MfA6Wndt4H/Kmm2MkdKOlvS+9P6x4E/kzRBUjfw+6NffLMhewh4VdI1kg5P5+9Jkn53kP0eBN4GLkt/K/N552/FBuHk0GYi4i3gj4GLgH3A54A707otZNcdvpHW9abtKq4E/hB4GbiA7MK2WUtL1xL+EDgVeA54CbgF+MAg+1X+Vi4hO+f/I/BDsutwNgh5sh8zGy8kbQb+NiK+0+yytDrXHMxszJL0+5J+IzUrLQR+B7iv2eVqB+6tZGZj2QnAGuB9wE+BcyNiV3OL1B7crGRmZgVuVjIzs4K2bVY69thjY/r06QeXX3/9dY488sjmFegQtFuZx1p5H3nkkZci4oOjWKRhqT7nof3+TUaKv4dMQ8/5iGjLx6xZsyLvgQceiHbTbmUea+UFtkQLnMv1PqrP+Xo+43jh7yHTyHPezUpmZlbg5GDj2XRJeyQ9VQlIOlrSRknb0vPkFJekZZJ6JT2RRsCt7LMwbb8tdZesxGdJejLts6wyjMNA72HWSpwcbDx7Ceiuii0G7o+ImcD9aRngTGBmeiwCbobsP3pgCTCbbGiGJbn/7G9O21b26x7kPcxahpODjWf7gb1VsfnAyvR6JXBOLr4qNd1uAiZJmgKcAWyMiL0RsQ/YCHSndUdFxIOprXdV1bHK3sOsZdTVW0nSXwD/GQjgSeBiYArZBBtHA48Cfx4Rb6WJZVYBs4BfAp+LiB3pONeSjXPyNnBFRGxI8W7gJrJheG+JiKWN+oBmQ9QR6SapiNgl6bgUn0r/4Z77UqxWvK8kXus9CiQtIqt90NHRQU9PT7/1+/fvL8TGI38PmUZ+D4MmB0lTgSuAEyPiV5LWkE2ycRZwY0SslvS3ZP/p35ye90XERyUtAL4CfE7SiWm/j5GNs/5/JP1WeptvAp8h+wN6WNK6iHi6IZ/QrDFUEotDiA9JRCwHlgN0dnZGV1dXv/U9PT1Ux8Yjfw+ZRn4P9TYrTQQOTxNoHEE2TvqngLVpfXX1u1JlXgvMTRfi5gOrI+LNiHiObMTQ09OjNyK2RzaK4uq0rVkz7E5NQqTnPSneR/+5AKYBLwwSn1YSr/UeZi1j0JpDRPxc0leB54FfAT8CHgFejogDabN8lflgNTsiDkh6hWw+46nAptyh8/tUV8tnl5WlVhW7HauV7VbmcVLedcBCYGl6vjsXv0zSarLz85XUJLQB+KvcReh5wLURsTdNaj8H2AxcCPyvQd7DrGXU06w0meyX/AyyMdG/T9Zzo1qlyjzUanZZ7aW0+l2rit2O1cp2K/MYLO8MsglhjpXUR9braCmwRtIlZD+IzkvbridrSu0lm1HvYoCUBL7MO/N4XxcRlYvcXyCb3P5w4N70oMZ7mLWMei5If5psir4XASTdCfweWW+Nian2kK8yV6rZfakZ6gNkPUIGqn5TIz4ipi++p9/yjqVnj+TbWet6LiI6S+JzqwOpx9GlZQeJiBXAipL4FuCkkvgvy96jkXyO23DVc83heWCOpCPStYO5wNPAA8C5aZvq6nflRqBzgR+nP6x1wAJJ75E0g6zf90Nkv7hmSpoh6TCyi9brhv/RzMzsUNVzzWGzpLVk3VUPAI+RNe3cA6yWdH2K3Zp2uRW4XVIvWY1hQTrO1tTT6el0nEsjm/4PSZcBG8i6sq6IiK2N+4hmZjZUdd3nEBFLyNpj87ZTMll3RPyaAdpQI+IG4IaS+HqyNl0zM2sBvkPazMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCgZNDpJOkPR47vGqpKskHS1po6Rt6Xly2l6SlknqlfSEpNNyx1qYtt8maWEuPkvSk2mfZWmuajMza5JBk0NEPBsRp0bEqcAs4A3gLmAxcH9EzATuT8sAZwIz02MRcDOApKPJphqdTTa96JJKQknbLMrt192QT2dmZodkqM1Kc4GfRsTPgPnAyhRfCZyTXs8HVkVmEzBJ0hTgDGBjROyNiH3ARqA7rTsqIh6MiABW5Y5lZmZNMHGI2y8A7kivOyJiF0BE7JJ0XIpPBXbm9ulLsVrxvpJ4gaRFZDUMOjo66OnpObhu//79/ZZrufrkA/2W692v0YZS5lbg8pqNH3UnB0mHAZ8Frh1s05JYHEK8GIxYDiwH6OzsjK6uroPrenp6yC/XctHie/ot77igvv0abShlbgUur9n4MZRmpTOBRyNid1renZqESM97UrwPOD633zTghUHi00riZmbWJENJDufzTpMSwDqg0uNoIXB3Ln5h6rU0B3glNT9tAOZJmpwuRM8DNqR1r0mak3opXZg7lpmZNUFdzUqSjgA+A3w+F14KrJF0CfA8cF6KrwfOAnrJejZdDBAReyV9GXg4bXddROxNr78A3AYcDtybHmZm1iR1JYeIeAM4pir2S7LeS9XbBnDpAMdZAawoiW8BTqqnLGZmNvKG2lupLU2vugBtZma1efgMMzMrcHIwM7MCJwczMytwcjArIekvJG2V9JSkOyS9V9IMSZvTwJHfSzeGIuk9abk3rZ+eO861Kf6spDNy8e4U65W0uFgCs+ZycjCrImkqcAXQGREnARPIho75CnBjGmxyH3BJ2uUSYF9EfBS4MW2HpBPTfh8jG0zybyRNkDQB+CbZjaUnAuenbc1ahpODWbmJwOGSJgJHALuATwFr0/rqwSYrg1CuBeamGzrnA6sj4s2IeI7s3p/T06M3IrZHxFvA6rStWcsYF11ZzYYiIn4u6atkN3f+CvgR8AjwckRURm3MDxB5cFDJiDgg6RWy+4KmAptyh87vUz0I5eyystQabBIGHlywVQaXHC0eZDHTyO/BycGsShreZT4wA3gZ+D5ZE1C1ygCRQx1UsqzGPuTBJmHgwQVbZXDJ0eJBFjON/B7crGRW9GnguYh4MSL+BbgT+D2yuUkqP6jyA0QeHFQyrf8AsJehD0Jp1jKcHMyKngfmSDoiXTuYCzwNPACcm7apHmyyMgjlucCP0zAy64AFqTfTDLJZDh8iG19sZur9dBjZRet1o/C5zOrmZiWzKhGxWdJa4FHgAPAYWdPOPcBqSden2K1pl1uB2yX1ktUYFqTjbJW0hiyxHAAujYi3ASRdRjZS8QRgRURsHa3PZ1YPJwezEhGxhGzO87ztZD2Nqrf9Ne+MSly97gbghpL4erIRjM1akpuVzMyswMnBzMwKnBzMzKzAycHMzArqSg6SJklaK+mfJT0j6d9JOlrSxjQI2cZ04xBp7uhlaUCxJySdljvOwrT9NkkLc/FZkp5M+yxL3QfNzKxJ6q053ATcFxH/FjgFeAZYDNyfBiG7Py1DdifpzPRYBNwMIOlost4fs8l6fCypJJS0zaLcft3D+1hmZjYcgyYHSUcBnyT16Y6ItyLiZfoPNlY9CNmqyGwiu6t0CnAGsDEi9kbEPmAj0J3WHRURD6Ybh1bljmVmZk1Qz30OHwFeBL4j6RSyAciuBDoiYhdAROySdFza/uAgZEllsLFa8b6SeEGtQchqDThVPQhZtWYN2NVug4W5vGbjRz3JYSJwGnB5unP0Jt5pQioz1EHIBooXgzUGIas14FT1IGTVmjUoWbsNFubymo0f9Vxz6AP6ImJzWl5Llix2pyYh0vOe3PZDGWysL72ujpuZWZMMmhwi4hfATkknpFBlELL8YGPVg5BdmHotzQFeSc1PG4B5kianC9HzgA1p3WuS5qReShfmjmVmZk1Q79hKlwPfTSNIbgcuJkssayRdQjaKZWVsmfXAWWSzXr2RtiUi9kr6MtmIlADXRcTe9PoLwG3A4cC96WFmZk1SV3KIiMeBzpJVc0u2DeDSAY6zAlhREt8CnFRPWczMbOT5DmkzMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrqCs5SNoh6UlJj0vakmJHS9ooaVt6npzikrRMUq+kJySdljvOwrT9NkkLc/FZ6fi9aV81+oOamVn9hlJz+A8RcWpEVKYLXQzcHxEzgfvTMsCZwMz0WATcDFkyAZYAs4HTgSWVhJK2WZTbr/uQP5GZmQ3bcJqV5gMr0+uVwDm5+KrIbAImSZoCnAFsjIi9EbEP2Ah0p3VHRcSDaf7pVbljmZlZE0ysc7sAfiQpgG9FxHKgIyJ2AUTELknHpW2nAjtz+/alWK14X0m8QNIishoGHR0d9PT0HFy3f//+fst5V598oOaHG2i/kVarzK1oPJVX0iTgFuAksvP/PwHPAt8DpgM7gD+NiH2pGfQm4CzgDeCiiHg0HWch8N/TYa+PiJUpPgu4DTgcWA9cmX4cmbWEepPDJyLihZQANkr65xrbll0viEOIF4NZUloO0NnZGV1dXQfX9fT0kF/Ou2jxPTWKCzsuKN9vpNUqcysaZ+W9CbgvIs6VdBhwBPBFsqbUpZIWkzWlXkP/ptTZZM2ks3NNqZ1k5/QjktalmnOlKXUTWXLoBu491MKaNVpdzUoR8UJ63gPcRXbNYHdqEiI970mb9wHH53afBrwwSHxaSdysKSQdBXwSuBUgIt6KiJdxU6qNI4MmB0lHSnp/5TUwD3gKWAdUehwtBO5Or9cBF6ZeS3OAV1Lz0wZgnqTJ6UL0PGBDWveapDmpen5h7lhmzfAR4EXgO5Iek3RLOvf7NaUCI96UatYs9TQrdQB3pd6lE4G/i4j7JD0MrJF0CfA8cF7afj1Z22svWfvrxQARsVfSl4GH03bXRcTe9PoLvNP+ei+uXltzTQROAy6PiM2SbuKd3nhlRqwptdZ1Nhj4ukr1dbZ2ulZ0KNrtethIaeT3MGhyiIjtwCkl8V8Cc0viAVw6wLFWACtK4lvILvyZtYI+oC8iNqfltWTJYbekKakDRr1NqV1V8R6G0JRa6zobDHxdpfo6W7Ouq42WdrseNlIa+T34DmmzKhHxC2CnpBNSaC7wNG5KtXGk3t5KZuPN5cB3U0+l7WTNo+/CTak2Tjg5mJWIiMfJuqBWc1OqjQtuVjIzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK6g7OUiakObT/WFaniFps6Rtkr6Xxr1H0nvScm9aPz13jGtT/FlJZ+Ti3SnWK6nWdIxmZjYKhlJzuBJ4Jrf8FeDGiJgJ7AMuSfFLgH0R8VHgxrQdkk4EFgAfA7qBv0kJZwLwTeBM4ETg/LStmZk1SV3JQdI04GzglrQs4FNkc+sCrATOSa/np2XS+rlp+/nA6oh4MyKeI5s16/T06I2I7RHxFrA6bWtmZk1S70xwXwf+G/D+tHwM8HJEHEjLfcDU9HoqsBMgIg5IeiVtPxXYlDtmfp+dVfHZZYWQtAhYBNDR0UFPT8/Bdfv37++3nHf1yQdK4xUD7TfSapW5Fbm8ZuPHoMlB0h8AeyLiEUldlXDJpjHIuoHiZbWXKIkREcuB5QCdnZ3R1dV1cF1PTw/55byLFt9TGq/YcUH5fiOtVplbkctrNn7UU3P4BPBZSWcB7wWOIqtJTJI0MdUepgEvpO37gOOBPkkTgQ8Ae3Pxivw+A8XNzKwJBr3mEBHXRsS0iJhOdkH5xxFxAfAAcG7abCFwd3q9Li2T1v84TcC+DliQejPNAGYCDwEPAzNT76fD0nusa8inMzOzQ1LvNYcy1wCrJV0PPAbcmuK3ArdL6iWrMSwAiIitktYATwMHgEsj4m0ASZcBG4AJwIqI2DqMcpmZ2TANKTlERA/Qk15vJ+tpVL3Nr4HzBtj/BuCGkvh6YP1QymJmZiPHd0ibmVmBk4OZmRU4OZiZWcFwLkibWQuYPsh9PGaHwjUHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwG4DnTbfxzMnBbGCeN93GLScHsxKeN93GOw+fYVau5edNh2ye7KtPfnvQDzPW59L2fOGZRn4PTg5mVdpl3nTI/tP/2k9eL9u1vyeL2+xYevbg+7UJzxeeaeT34ORgVuR5023cG/Sag6T3SnpI0j9J2irpf6S4e27YmOR5083quyD9JvCpiDgFOBXoljQH99yw8eca4C/T/OjH0H/e9GNS/C+BxZDNmw5U5k2/jzRveqp5VOZNfwZY43nTrdUM2qyUfgHtT4vvTo8g67nxZym+EvgScDNZr4svpfha4BvVPTeA59IfUmUO6t40JzWSKj03nh7OBzNrBM+bbuNVXdcc0q/7R4CPkv3K/ykt1nOj1lX6q08+UBqvaFYvh3brYeHymo0fdSWHiHgbOFXSJOAu4LfLNkvPTem5Uesq/UWDzJS144Ly/UZau/WwcHnNxo8h3QQXES+TVbHnkHpupFVlPTeos+dGrR4dZmbWBPX0VvpgqjEg6XDg02QX0dxzw8xsjKqnWWkKsDJdd3gXWc+KH0p6Glgt6XrgMfr33Lg9XXDeS/afPRGxVVKl58YBUs8NAEmVnhsTgBXuuWFm1lz19FZ6Avh4Sdw9N8zMxigPvGdmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYF9cwhfbykByQ9I2mrpCtT/GhJGyVtS8+TU1ySlknqlfSEpNNyx1qYtt8maWEuPkvSk2mfZZI0Eh/WzMzqU0/N4QBwdUT8NjAHuFTSicBi4P6ImAncn5YBzgRmpsci4GbIkgmwBJhNNr3okkpCSdssyu3XPfyPZmZmh6qeOaR3AbvS69ckPQNMBeYDXWmzlUAPcE2Kr4qIADZJmiRpStp2Y0TsBZC0EeiW1AMcFREPpvgq4Bzg3sZ8xMFNX3xPIbZj6dmj9fZmZi1nSNccJE0HPg5sBjpS4qgkkOPSZlOBnbnd+lKsVryvJG5mZk0yaM2hQtL7gB8AV0XEqzUuC5StiEOIl5VhEVnzEx0dHfT09Bxct3///n7LeVeffGCgsg5ooGM1Uq0ytyKX12z8qCs5SHo3WWL4bkTcmcK7JU2JiF2p2WhPivcBx+d2nwa8kOJdVfGeFJ9Wsn1BRCwHlgN0dnZGV9c7h+vp6SG/nHdRSbPRYHZcUH6sRqpV5lbk8pqNH/X0VhJwK/BMRPx1btU6oNLjaCFwdy5+Yeq1NAd4JTU7bQDmSZqcLkTPAzakda9JmpPe68LcsczMrAnqqTl8Avhz4ElJj6fYF4GlwBpJlwDPA+eldeuBs4Be4A3gYoCI2Cvpy8DDabvrKhengS8AtwGHk12IHrWL0WZmVlRPb6WfUH5dAGBuyfYBXDrAsVYAK0riW4CTBiuLmZmNDt8hbWZmBU4OZlU8KoCZk4NZGY8KYOOek4NZlYjYFRGPptevAflRAVamzVaS3ckPuVEBImITUBkV4AzSqAARsQ+ojAowhTQqQLpGtyp3LLOWUPdNcGbjUa1RASSN+KgAtW78hOxGv6tPfnvoH4zRudFztPiGx0wjvwcnB7MBtMKoALVu/ITsP/iv/eT1gcpV02jc6DlafMNjppHfg5uVzErUGhUgra93VICB4nWNCmDWLE4OZlU8KoCZm5XMynhUABv3xlxyKJubwWwoPCqAmZuVzMyshJODmZkVODmYmVmBk4OZmRU4OZiZWYGTg5mZFTg5mJlZgZODmZkVDJocJK2QtEfSU7mYJz0xMxvD6qk53EZxIhJPemJmNoYNOnxGRPxDGtM+bz7QlV6vBHqAa8hNegJsklSZ9KSLNOkJgKTKpCc9pElPUrwy6UnTx5mpHoZjx9Kzm1QSM7PRd6hjK436pCdQe+KTyiQXV5984BA/Um0jMZFIu01Q4vKajR+NHnhvxCY9gdoTn1QmubhohAbeG4mJUdptghKX12z8ONTksFvSlFRrqHfSk66qeA+e9MSsadx0arUcaldWT3piZjaGDVpzkHQH2a/+YyX1kfU68qQnZmZjWD29lc4fYJUnPTEzG6N8h7SZmRU4OZiZWYGTg5mZFTg5mJlZgZODmZkVODmYmVmBk4OZmRU4OZiZWYGTg5mZFTg5mJlZgZODmZkVODmYmVmBk4OZmRU4OZiZWUGjpwkds6pnzQLPnGVmY5drDmZmVuCag5kBnlPa+muZ5CCpG7gJmADcEhFLm1ykQfmPyYajHc95Gz9aollJ0gTgm8CZwInA+ZJObG6pzEaOz3lrda1Sczgd6I2I7QCSVgPzgaebWqohKrtoXc21C0ta/pz3+Ty+tUpymArszC33AbOrN5K0CFiUFvdLeja3+ljgpRErYYPoK/0W26LMOWOtvB8erYKUaMQ5D03+N6k6n5up3c7NkdKwc75VkoNKYlEIRCwHlpceQNoSEZ2NLthIarcyu7wNNexzHlr+M44afw+ZRn4PLXHNgexX0/G55WnAC00qi9lo8DlvLa1VksPDwExJMyQdBiwA1jW5TGYjyee8tbSWaFaKiAOSLgM2kHXrWxERW4d4mAGr3i2s3crs8jZIg855aOHPOMr8PWQa9j0ootDMaWZm41yrNCuZmVkLcXIwM7OCMZEcJHVLelZSr6TFzS5PNUnHS3pA0jOStkq6MsW/JOnnkh5Pj7OaXdYKSTskPZnKtSXFjpa0UdK29Dy52eUEkHRC7jt8XNKrkq5q5e+3EVr9vB9J7XR+NpKkFZL2SHoqFyv93MosS+fHE5JOG9J7tfs1hzQMwf8DPkPWPfBh4PyIaJk7TSVNAaZExKOS3g88ApwD/CmwPyK+2tQClpC0A+iMiJdysf8J7I2Ipek/o8kRcU2zylgmnQ8/J7uh7GJa9PsdrnY470dSu56fwyXpk8B+YFVEnJRipZ87/Ri6HDiL7O/hpogo3Gg5kLFQczg4DEFEvAVUhiFoGRGxKyIeTa9fA54hu0O23cwHVqbXK8kSXKuZC/w0In7W7IKMsJY/75ugHc7PYYmIfwD2VoUH+tzzyZJIRMQmYFL6oVqXsZAcyoYhaNn/eCVNBz4ObE6hy1KVb0WLVYMD+JGkR9IQDgAdEbELsoQHHNe00g1sAXBHbrlVv9/haqvzfgS06/k5Egb63MM6R8ZCcqhrGIJWIOl9wA+AqyLiVeBm4N8ApwK7gK81sXjVPhERp5GNGnppqs62tHQz2WeB76dQK3+/w9U25/0IabvzswmGdY6MheTQFsMQSHo3WWL4bkTcCRARuyPi7Yj4V+DbZE0FLSEiXkjPe4C7yMq2u1ItTc97mlfCUmcCj0bEbmjt77cB2uK8Hylten6OlIE+97DOkbGQHFp+GAJJAm4FnomIv87F8+1/fwQ8Vb1vM0g6Ml04R9KRwDyysq0DFqbNFgJ3N6eEAzqfXJNSq36/DdLy5/1IaePzc6QM9LnXARemXktzgFcqzU/1aPveSgDpqvzXeWcYghuaXKR+JP174B+BJ4F/TeEvkv1ndipZVW8H8Pmh/OONFEkfIfs1BtkQK38XETdIOgZYA/wm8DxwXkRUXxxrCklHkLWvfiQiXkmx22nB77dRWv28HynteH42iqQ7gC6yobl3A0uAv6fkc6cfpd8AuoE3gIsjYkvd7zUWkoOZmTXWWGhWMjOzBnNyMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK/j/xuZrjgq+LHYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 16172\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 35021\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length= in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences = True))\n",
    "      model.add(Dense(out_vocab, activation = 'softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 08:50:19.566350 123248 deprecation_wrapper.py:119] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0828 08:50:19.581350 123248 deprecation_wrapper.py:119] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0828 08:50:19.585350 123248 deprecation_wrapper.py:119] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0828 08:50:20.042350 123248 deprecation.py:323] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# model compilation\n",
    "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 08:50:23.763350 123248 deprecation_wrapper.py:119] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0828 08:50:23.770350 123248 deprecation_wrapper.py:119] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 08:50:27.182350 123248 deprecation_wrapper.py:119] From C:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125341 samples, validate on 31336 samples\n",
      "Epoch 1/30\n",
      "125341/125341 [==============================] - 877s 7ms/step - loss: 4.9479 - val_loss: 4.7883\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.78832, saving model to model.h1.24_jan_19\n",
      "Epoch 2/30\n",
      "125341/125341 [==============================] - 862s 7ms/step - loss: 4.3793 - val_loss: 4.2021\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.78832 to 4.20209, saving model to model.h1.24_jan_19\n",
      "Epoch 3/30\n",
      "125341/125341 [==============================] - 850s 7ms/step - loss: 3.9426 - val_loss: 3.7887\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.20209 to 3.78867, saving model to model.h1.24_jan_19\n",
      "Epoch 4/30\n",
      "125341/125341 [==============================] - 861s 7ms/step - loss: 3.5390 - val_loss: 3.4422\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.78867 to 3.44222, saving model to model.h1.24_jan_19\n",
      "Epoch 5/30\n",
      "125341/125341 [==============================] - 863s 7ms/step - loss: 3.1831 - val_loss: 3.1651\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.44222 to 3.16508, saving model to model.h1.24_jan_19\n",
      "Epoch 6/30\n",
      "125341/125341 [==============================] - 875s 7ms/step - loss: 2.8804 - val_loss: 2.9529\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.16508 to 2.95294, saving model to model.h1.24_jan_19\n",
      "Epoch 7/30\n",
      "125341/125341 [==============================] - 834s 7ms/step - loss: 2.6239 - val_loss: 2.7917\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.95294 to 2.79169, saving model to model.h1.24_jan_19\n",
      "Epoch 8/30\n",
      "125341/125341 [==============================] - 923s 7ms/step - loss: 2.4100 - val_loss: 2.7140\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.79169 to 2.71402, saving model to model.h1.24_jan_19\n",
      "Epoch 9/30\n",
      "125341/125341 [==============================] - 974s 8ms/step - loss: 2.2277 - val_loss: 2.5808\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.71402 to 2.58081, saving model to model.h1.24_jan_19\n",
      "Epoch 10/30\n",
      "  1024/125341 [..............................] - ETA: 14:35 - loss: 2.0378"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-212595acfee8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n\u001b[0;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\M316375\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.24_jan_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-314735a9fdda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>the barns on fire</td>\n",
       "      <td>the gate closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>do you want me to wait</td>\n",
       "      <td>do you want me to wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>be polite to everyone</td>\n",
       "      <td>be  polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>the story was amusing</td>\n",
       "      <td>the story was true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>he continued singing</td>\n",
       "      <td>he went singing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918</th>\n",
       "      <td>tom cant sing</td>\n",
       "      <td>tom cant sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>tom has a plan</td>\n",
       "      <td>tom has a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7654</th>\n",
       "      <td>were brothers</td>\n",
       "      <td>were are brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>everybody likes you</td>\n",
       "      <td>everybody likes you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>ill take you with me</td>\n",
       "      <td>ill taking you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>youve found it</td>\n",
       "      <td>they found it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>i was really pleased</td>\n",
       "      <td>i was really depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>get to the point</td>\n",
       "      <td>come to the while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>hes an englishman</td>\n",
       "      <td>he is english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>do you have a vacancy</td>\n",
       "      <td>did you out my room</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual                   predicted\n",
       "7860       the barns on fire        the gate closed     \n",
       "7409  do you want me to wait    do you want me to wait  \n",
       "377    be polite to everyone             be  polite     \n",
       "3521   the story was amusing      the story was true    \n",
       "4888    he continued singing        he went singing     \n",
       "6918           tom cant sing          tom cant sing     \n",
       "6325          tom has a plan              tom has a     \n",
       "7654           were brothers      were are brothers     \n",
       "8234     everybody likes you    everybody likes you     \n",
       "4347    ill take you with me         ill taking you     \n",
       "8975          youve found it          they found it     \n",
       "2459    i was really pleased  i was really depressed    \n",
       "6427        get to the point       come to the while    \n",
       "5845       hes an englishman          he is english     \n",
       "6376   do you have a vacancy      did you out my room   "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
